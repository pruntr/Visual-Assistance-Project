# Visual-Assistance-Project



Designed for the blind and low vision community, this research project harnesses
the power of machine learning to describe people, text, and objects. This project brings together
the power of ml to deliver an intelligent system designed to help you navigate your
day. Point your phone’s camera, select a channel, and hear a description of what the
model has recognized around you.




With its intelligent system, just hold up your camera and hear information about the
world around you. Our system will speak short text as it appears in front of the
camera, provide audio guidance to capture a printed page, and recognize and narrate
the text.


● Recognize and locate the objects you’re with.


● Reads text quickly and gets audio guidance to capture full documents.


Our project will be an extended work of real-time object detection. We will
implement real-time object detection using COCO API, which detects the object
on live video stream and converts the objects to speech, and give a gist of where
the object is.



